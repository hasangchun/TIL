{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(l):\n",
    "    return list(itertools.chain.from_iterable(l))\n",
    "\n",
    "seqs = ['ghatmasala', 'nicela', 'chutpakodas']\n",
    "vocab = ['<pad>'] + sorted(list(set(flatten(seqs))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vectorized_seqs [[5, 6, 1, 15, 10, 1, 14, 1, 9, 1], [11, 7, 2, 4, 9, 1], [2, 6, 16, 15, 13, 1, 8, 12, 3, 1, 14]]\n"
     ]
    }
   ],
   "source": [
    "embedding_size = 3\n",
    "embed = nn.Embedding(len(vocab), embedding_size)\n",
    "lstm = nn.LSTM(embedding_size, 5)\n",
    "\n",
    "vectorized_seqs = [[vocab.index(tok) for tok in seq]for seq in seqs]\n",
    "print(\"vectorized_seqs\", vectorized_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 6, 11]\n"
     ]
    }
   ],
   "source": [
    "print([x for x in map(len, vectorized_seqs)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq_tensor tensor([[ 5,  6,  1, 15, 10,  1, 14,  1,  9,  1,  0],\n",
      "        [11,  7,  2,  4,  9,  1,  0,  0,  0,  0,  0],\n",
      "        [ 2,  6, 16, 15, 13,  1,  8, 12,  3,  1, 14]])\n"
     ]
    }
   ],
   "source": [
    "seq_lengths = torch.LongTensor([x for x in map(len, vectorized_seqs)])\n",
    "\n",
    "seq_tensor = Variable(torch.zeros((len(vectorized_seqs),seq_lengths.max()))).long()\n",
    "for idx, (seq, seqlen) in enumerate(zip(vectorized_seqs, seq_lengths)):\n",
    "    seq_tensor[idx, :seqlen] = torch.LongTensor(seq)\n",
    "    \n",
    "print(\"seq_tensor\", seq_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq_tensor after sorting tensor([[ 2,  6, 16, 15, 13,  1,  8, 12,  3,  1, 14],\n",
      "        [ 5,  6,  1, 15, 10,  1, 14,  1,  9,  1,  0],\n",
      "        [11,  7,  2,  4,  9,  1,  0,  0,  0,  0,  0]])\n"
     ]
    }
   ],
   "source": [
    "# SORT YOUR TENSORS BY LENGTH!\n",
    "seq_lengths, perm_idx = seq_lengths.sort(0, descending=True)\n",
    "seq_tensor = seq_tensor[perm_idx]\n",
    "print(\"seq_tensor after sorting\", seq_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq_tensor after transposing torch.Size([11, 3]) tensor([[ 2,  5, 11],\n",
      "        [ 6,  6,  7],\n",
      "        [16,  1,  2],\n",
      "        [15, 15,  4],\n",
      "        [13, 10,  9],\n",
      "        [ 1,  1,  1],\n",
      "        [ 8, 14,  0],\n",
      "        [12,  1,  0],\n",
      "        [ 3,  9,  0],\n",
      "        [ 1,  1,  0],\n",
      "        [14,  0,  0]])\n"
     ]
    }
   ],
   "source": [
    "seq_tensor = seq_tensor.transpose(0, 1)  # (B,L,D) -> (L,B,D)\n",
    "print(\"seq_tensor after transposing\", seq_tensor.size(), seq_tensor.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq_tensor after embeding torch.Size([11, 3, 3]) tensor([[ 2,  5, 11],\n",
      "        [ 6,  6,  7],\n",
      "        [16,  1,  2],\n",
      "        [15, 15,  4],\n",
      "        [13, 10,  9],\n",
      "        [ 1,  1,  1],\n",
      "        [ 8, 14,  0],\n",
      "        [12,  1,  0],\n",
      "        [ 3,  9,  0],\n",
      "        [ 1,  1,  0],\n",
      "        [14,  0,  0]])\n"
     ]
    }
   ],
   "source": [
    "embeded_seq_tensor = embed(seq_tensor)\n",
    "print(\"seq_tensor after embeding\", embeded_seq_tensor.size(), seq_tensor.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lstm output torch.Size([11, 3, 5]) tensor([[[-0.0695,  0.0401,  0.0505, -0.0021,  0.0710],\n",
      "         [-0.0071, -0.0545, -0.0546, -0.0356,  0.1264],\n",
      "         [-0.0253,  0.0235,  0.1605,  0.0986,  0.0624]],\n",
      "\n",
      "        [[ 0.0298,  0.0532,  0.1270,  0.0362,  0.2236],\n",
      "         [ 0.0401, -0.0080,  0.0937,  0.0267,  0.2443],\n",
      "         [-0.1020, -0.1217, -0.1543, -0.0785,  0.0429]],\n",
      "\n",
      "        [[-0.0251,  0.0275,  0.2128,  0.1310,  0.0806],\n",
      "         [-0.0846, -0.0221, -0.0019, -0.0152,  0.0401],\n",
      "         [-0.0877, -0.0169,  0.0343, -0.0340,  0.0819]],\n",
      "\n",
      "        [[ 0.0377, -0.1428, -0.0945, -0.0795,  0.2093],\n",
      "         [ 0.0072, -0.2050, -0.1701, -0.1549,  0.2076],\n",
      "         [-0.1389, -0.1500, -0.2347, -0.2065, -0.0156]],\n",
      "\n",
      "        [[-0.0033, -0.0921,  0.0249, -0.0430,  0.2613],\n",
      "         [ 0.0516, -0.0291,  0.1964,  0.1199,  0.1719],\n",
      "         [-0.1173, -0.1029, -0.0423, -0.1234,  0.0436]],\n",
      "\n",
      "        [[-0.0978, -0.0696, -0.0083, -0.0679,  0.0387],\n",
      "         [-0.0693, -0.0515, -0.0232,  0.0143,  0.0131],\n",
      "         [-0.1397, -0.0540, -0.0331, -0.1074, -0.0399]],\n",
      "\n",
      "        [[ 0.1519, -0.0087,  0.1280,  0.0614,  0.2928],\n",
      "         [-0.0203, -0.0485,  0.0020,  0.0229,  0.1177],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[-0.0117,  0.0071,  0.0876,  0.0510,  0.1514],\n",
      "         [-0.1075, -0.0424, -0.0347, -0.0312,  0.0082],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[-0.0906, -0.0665, -0.0530, -0.0358,  0.0781],\n",
      "         [-0.1030, -0.0346, -0.0203, -0.0501,  0.0465],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[-0.1275, -0.0325, -0.0378, -0.0639, -0.0174],\n",
      "         [-0.1354, -0.0145, -0.0307, -0.0697, -0.0305],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[-0.0417, -0.0366,  0.0106, -0.0256,  0.1122],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]])\n",
      "Last output torch.Size([3, 5]) tensor([[-0.0417, -0.0366,  0.0106, -0.0256,  0.1122],\n",
      "        [-0.1354, -0.0145, -0.0307, -0.0697, -0.0305],\n",
      "        [-0.1397, -0.0540, -0.0331, -0.1074, -0.0399]])\n"
     ]
    }
   ],
   "source": [
    "# pack them up nicely\n",
    "packed_input = pack_padded_sequence(\n",
    "    embeded_seq_tensor, seq_lengths.cpu().numpy())\n",
    "packed_output, (ht, ct) = lstm(packed_input)\n",
    "\n",
    "# unpack your output\n",
    "output, _ = pad_packed_sequence(packed_output)\n",
    "print(\"Lstm output\", output.size(), output.data)\n",
    "# the final hidden state\n",
    "print(\"Last output\", ht[-1].size(), ht[-1].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
