{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MNIST Model on cpu\n",
      "============================================\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from torch import nn, optim, cuda\n",
    "from torch.utils import data\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "\n",
    "batch_size = 64\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "print(f'Training MNIST Model on {device}\\n{\"=\" * 44}')\n",
    "\n",
    "# MNIST Dataset\n",
    "train_dataset = datasets.MNIST(root = './mnist_data/',\n",
    "                             train = True,\n",
    "                             transform = transforms.ToTensor(),\n",
    "                             download = True)\n",
    "\n",
    "test_dataset = datasets.MNIST(root = './mnist_data/',\n",
    "                             train = False,\n",
    "                             transform = transforms.ToTensor())\n",
    "\n",
    "# Data Loader \n",
    "train_loader = data.DataLoader(dataset = train_dataset,\n",
    "                              batch_size = batch_size,\n",
    "                              shuffle = True)\n",
    "test_loader = data.DataLoader(dataset = test_dataset,\n",
    "                             batch_size = batch_size,\n",
    "                             shuffle = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.l1 = nn.Linear(784, 520)\n",
    "        self.l2 = nn.Linear(520, 320)\n",
    "        self.l3 = nn.Linear(320, 240)\n",
    "        self.l4 = nn.Linear(240, 120)\n",
    "        self.l5 = nn.Linear(120, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 784)  # Flatten the data (n, 1, 28, 28) -> (n, 784)\n",
    "        x = F.relu(self.l1(x))\n",
    "        x = F.relu(self.l2(x))\n",
    "        x = F.relu(self.l3(x))\n",
    "        x = F.relu(self.l4(x))\n",
    "        return self.l5(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # Print\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} | Batch Status: {}/{} ({:.0f}%) | Loss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "        # sum up batch loss\n",
    "        test_loss += criterion(output, target).item()\n",
    "        # get the index of the max\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print(f'===========================\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} '\n",
    "          f'({100. * correct / len(test_loader.dataset):.0f}%)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 | Batch Status: 0/60000 (0%) | Loss: 2.311743\n",
      "Train Epoch: 1 | Batch Status: 640/60000 (1%) | Loss: 2.311398\n",
      "Train Epoch: 1 | Batch Status: 1280/60000 (2%) | Loss: 2.303400\n",
      "Train Epoch: 1 | Batch Status: 1920/60000 (3%) | Loss: 2.314534\n",
      "Train Epoch: 1 | Batch Status: 2560/60000 (4%) | Loss: 2.316975\n",
      "Train Epoch: 1 | Batch Status: 3200/60000 (5%) | Loss: 2.311316\n",
      "Train Epoch: 1 | Batch Status: 3840/60000 (6%) | Loss: 2.309283\n",
      "Train Epoch: 1 | Batch Status: 4480/60000 (7%) | Loss: 2.302307\n",
      "Train Epoch: 1 | Batch Status: 5120/60000 (9%) | Loss: 2.301988\n",
      "Train Epoch: 1 | Batch Status: 5760/60000 (10%) | Loss: 2.304562\n",
      "Train Epoch: 1 | Batch Status: 6400/60000 (11%) | Loss: 2.308523\n",
      "Train Epoch: 1 | Batch Status: 7040/60000 (12%) | Loss: 2.296128\n",
      "Train Epoch: 1 | Batch Status: 7680/60000 (13%) | Loss: 2.299294\n",
      "Train Epoch: 1 | Batch Status: 8320/60000 (14%) | Loss: 2.301234\n",
      "Train Epoch: 1 | Batch Status: 8960/60000 (15%) | Loss: 2.301702\n",
      "Train Epoch: 1 | Batch Status: 9600/60000 (16%) | Loss: 2.303107\n",
      "Train Epoch: 1 | Batch Status: 10240/60000 (17%) | Loss: 2.299242\n",
      "Train Epoch: 1 | Batch Status: 10880/60000 (18%) | Loss: 2.297538\n",
      "Train Epoch: 1 | Batch Status: 11520/60000 (19%) | Loss: 2.290535\n",
      "Train Epoch: 1 | Batch Status: 12160/60000 (20%) | Loss: 2.300547\n",
      "Train Epoch: 1 | Batch Status: 12800/60000 (21%) | Loss: 2.292472\n",
      "Train Epoch: 1 | Batch Status: 13440/60000 (22%) | Loss: 2.293449\n",
      "Train Epoch: 1 | Batch Status: 14080/60000 (23%) | Loss: 2.298075\n",
      "Train Epoch: 1 | Batch Status: 14720/60000 (25%) | Loss: 2.291261\n",
      "Train Epoch: 1 | Batch Status: 15360/60000 (26%) | Loss: 2.296144\n",
      "Train Epoch: 1 | Batch Status: 16000/60000 (27%) | Loss: 2.284814\n",
      "Train Epoch: 1 | Batch Status: 16640/60000 (28%) | Loss: 2.294556\n",
      "Train Epoch: 1 | Batch Status: 17280/60000 (29%) | Loss: 2.294433\n",
      "Train Epoch: 1 | Batch Status: 17920/60000 (30%) | Loss: 2.295474\n",
      "Train Epoch: 1 | Batch Status: 18560/60000 (31%) | Loss: 2.296615\n",
      "Train Epoch: 1 | Batch Status: 19200/60000 (32%) | Loss: 2.284996\n",
      "Train Epoch: 1 | Batch Status: 19840/60000 (33%) | Loss: 2.279428\n",
      "Train Epoch: 1 | Batch Status: 20480/60000 (34%) | Loss: 2.292738\n",
      "Train Epoch: 1 | Batch Status: 21120/60000 (35%) | Loss: 2.292111\n",
      "Train Epoch: 1 | Batch Status: 21760/60000 (36%) | Loss: 2.297080\n",
      "Train Epoch: 1 | Batch Status: 22400/60000 (37%) | Loss: 2.295441\n",
      "Train Epoch: 1 | Batch Status: 23040/60000 (38%) | Loss: 2.286627\n",
      "Train Epoch: 1 | Batch Status: 23680/60000 (39%) | Loss: 2.285663\n",
      "Train Epoch: 1 | Batch Status: 24320/60000 (41%) | Loss: 2.285323\n",
      "Train Epoch: 1 | Batch Status: 24960/60000 (42%) | Loss: 2.284850\n",
      "Train Epoch: 1 | Batch Status: 25600/60000 (43%) | Loss: 2.292011\n",
      "Train Epoch: 1 | Batch Status: 26240/60000 (44%) | Loss: 2.285436\n",
      "Train Epoch: 1 | Batch Status: 26880/60000 (45%) | Loss: 2.288246\n",
      "Train Epoch: 1 | Batch Status: 27520/60000 (46%) | Loss: 2.277092\n",
      "Train Epoch: 1 | Batch Status: 28160/60000 (47%) | Loss: 2.289991\n",
      "Train Epoch: 1 | Batch Status: 28800/60000 (48%) | Loss: 2.282735\n",
      "Train Epoch: 1 | Batch Status: 29440/60000 (49%) | Loss: 2.268442\n",
      "Train Epoch: 1 | Batch Status: 30080/60000 (50%) | Loss: 2.286636\n",
      "Train Epoch: 1 | Batch Status: 30720/60000 (51%) | Loss: 2.278969\n",
      "Train Epoch: 1 | Batch Status: 31360/60000 (52%) | Loss: 2.275786\n",
      "Train Epoch: 1 | Batch Status: 32000/60000 (53%) | Loss: 2.272879\n",
      "Train Epoch: 1 | Batch Status: 32640/60000 (54%) | Loss: 2.268283\n",
      "Train Epoch: 1 | Batch Status: 33280/60000 (55%) | Loss: 2.269395\n",
      "Train Epoch: 1 | Batch Status: 33920/60000 (57%) | Loss: 2.267645\n",
      "Train Epoch: 1 | Batch Status: 34560/60000 (58%) | Loss: 2.275675\n",
      "Train Epoch: 1 | Batch Status: 35200/60000 (59%) | Loss: 2.269740\n",
      "Train Epoch: 1 | Batch Status: 35840/60000 (60%) | Loss: 2.273342\n",
      "Train Epoch: 1 | Batch Status: 36480/60000 (61%) | Loss: 2.259830\n",
      "Train Epoch: 1 | Batch Status: 37120/60000 (62%) | Loss: 2.262326\n",
      "Train Epoch: 1 | Batch Status: 37760/60000 (63%) | Loss: 2.270463\n",
      "Train Epoch: 1 | Batch Status: 38400/60000 (64%) | Loss: 2.251620\n",
      "Train Epoch: 1 | Batch Status: 39040/60000 (65%) | Loss: 2.264951\n",
      "Train Epoch: 1 | Batch Status: 39680/60000 (66%) | Loss: 2.259245\n",
      "Train Epoch: 1 | Batch Status: 40320/60000 (67%) | Loss: 2.239583\n",
      "Train Epoch: 1 | Batch Status: 40960/60000 (68%) | Loss: 2.255775\n",
      "Train Epoch: 1 | Batch Status: 41600/60000 (69%) | Loss: 2.232935\n",
      "Train Epoch: 1 | Batch Status: 42240/60000 (70%) | Loss: 2.232035\n",
      "Train Epoch: 1 | Batch Status: 42880/60000 (71%) | Loss: 2.235040\n",
      "Train Epoch: 1 | Batch Status: 43520/60000 (72%) | Loss: 2.235724\n",
      "Train Epoch: 1 | Batch Status: 44160/60000 (74%) | Loss: 2.251707\n",
      "Train Epoch: 1 | Batch Status: 44800/60000 (75%) | Loss: 2.221064\n",
      "Train Epoch: 1 | Batch Status: 45440/60000 (76%) | Loss: 2.221700\n",
      "Train Epoch: 1 | Batch Status: 46080/60000 (77%) | Loss: 2.198323\n",
      "Train Epoch: 1 | Batch Status: 46720/60000 (78%) | Loss: 2.208566\n",
      "Train Epoch: 1 | Batch Status: 47360/60000 (79%) | Loss: 2.198157\n",
      "Train Epoch: 1 | Batch Status: 48000/60000 (80%) | Loss: 2.159848\n",
      "Train Epoch: 1 | Batch Status: 48640/60000 (81%) | Loss: 2.171053\n",
      "Train Epoch: 1 | Batch Status: 49280/60000 (82%) | Loss: 2.126328\n",
      "Train Epoch: 1 | Batch Status: 49920/60000 (83%) | Loss: 2.168942\n",
      "Train Epoch: 1 | Batch Status: 50560/60000 (84%) | Loss: 2.144828\n",
      "Train Epoch: 1 | Batch Status: 51200/60000 (85%) | Loss: 2.119093\n",
      "Train Epoch: 1 | Batch Status: 51840/60000 (86%) | Loss: 2.066686\n",
      "Train Epoch: 1 | Batch Status: 52480/60000 (87%) | Loss: 2.039613\n",
      "Train Epoch: 1 | Batch Status: 53120/60000 (88%) | Loss: 1.986116\n",
      "Train Epoch: 1 | Batch Status: 53760/60000 (90%) | Loss: 1.975309\n",
      "Train Epoch: 1 | Batch Status: 54400/60000 (91%) | Loss: 1.954347\n",
      "Train Epoch: 1 | Batch Status: 55040/60000 (92%) | Loss: 1.919487\n",
      "Train Epoch: 1 | Batch Status: 55680/60000 (93%) | Loss: 1.815585\n",
      "Train Epoch: 1 | Batch Status: 56320/60000 (94%) | Loss: 1.835092\n",
      "Train Epoch: 1 | Batch Status: 56960/60000 (95%) | Loss: 1.790954\n",
      "Train Epoch: 1 | Batch Status: 57600/60000 (96%) | Loss: 1.650683\n",
      "Train Epoch: 1 | Batch Status: 58240/60000 (97%) | Loss: 1.624597\n",
      "Train Epoch: 1 | Batch Status: 58880/60000 (98%) | Loss: 1.625855\n",
      "Train Epoch: 1 | Batch Status: 59520/60000 (99%) | Loss: 1.475597\n",
      "Training time: 0m 14s\n",
      "===========================\n",
      "Test set: Average loss: 0.0231, Accuracy: 6155/10000 (62%)\n",
      "Testing time: 0m 17s\n",
      "Train Epoch: 2 | Batch Status: 0/60000 (0%) | Loss: 1.448922\n",
      "Train Epoch: 2 | Batch Status: 640/60000 (1%) | Loss: 1.522008\n",
      "Train Epoch: 2 | Batch Status: 1280/60000 (2%) | Loss: 1.453465\n",
      "Train Epoch: 2 | Batch Status: 1920/60000 (3%) | Loss: 1.305682\n",
      "Train Epoch: 2 | Batch Status: 2560/60000 (4%) | Loss: 1.093979\n",
      "Train Epoch: 2 | Batch Status: 3200/60000 (5%) | Loss: 1.133077\n",
      "Train Epoch: 2 | Batch Status: 3840/60000 (6%) | Loss: 1.152895\n",
      "Train Epoch: 2 | Batch Status: 4480/60000 (7%) | Loss: 1.088241\n",
      "Train Epoch: 2 | Batch Status: 5120/60000 (9%) | Loss: 0.983796\n",
      "Train Epoch: 2 | Batch Status: 5760/60000 (10%) | Loss: 1.019457\n",
      "Train Epoch: 2 | Batch Status: 6400/60000 (11%) | Loss: 1.203828\n",
      "Train Epoch: 2 | Batch Status: 7040/60000 (12%) | Loss: 0.822422\n",
      "Train Epoch: 2 | Batch Status: 7680/60000 (13%) | Loss: 0.835477\n",
      "Train Epoch: 2 | Batch Status: 8320/60000 (14%) | Loss: 0.800759\n",
      "Train Epoch: 2 | Batch Status: 8960/60000 (15%) | Loss: 0.938039\n",
      "Train Epoch: 2 | Batch Status: 9600/60000 (16%) | Loss: 1.046478\n",
      "Train Epoch: 2 | Batch Status: 10240/60000 (17%) | Loss: 0.842224\n",
      "Train Epoch: 2 | Batch Status: 10880/60000 (18%) | Loss: 0.681959\n",
      "Train Epoch: 2 | Batch Status: 11520/60000 (19%) | Loss: 0.868670\n",
      "Train Epoch: 2 | Batch Status: 12160/60000 (20%) | Loss: 0.963456\n",
      "Train Epoch: 2 | Batch Status: 12800/60000 (21%) | Loss: 0.637673\n",
      "Train Epoch: 2 | Batch Status: 13440/60000 (22%) | Loss: 0.645296\n",
      "Train Epoch: 2 | Batch Status: 14080/60000 (23%) | Loss: 0.718156\n",
      "Train Epoch: 2 | Batch Status: 14720/60000 (25%) | Loss: 0.716873\n",
      "Train Epoch: 2 | Batch Status: 15360/60000 (26%) | Loss: 0.718112\n",
      "Train Epoch: 2 | Batch Status: 16000/60000 (27%) | Loss: 0.748930\n",
      "Train Epoch: 2 | Batch Status: 16640/60000 (28%) | Loss: 0.526596\n",
      "Train Epoch: 2 | Batch Status: 17280/60000 (29%) | Loss: 0.536855\n",
      "Train Epoch: 2 | Batch Status: 17920/60000 (30%) | Loss: 0.980474\n",
      "Train Epoch: 2 | Batch Status: 18560/60000 (31%) | Loss: 0.516299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 | Batch Status: 19200/60000 (32%) | Loss: 0.668020\n",
      "Train Epoch: 2 | Batch Status: 19840/60000 (33%) | Loss: 0.605097\n",
      "Train Epoch: 2 | Batch Status: 20480/60000 (34%) | Loss: 0.769416\n",
      "Train Epoch: 2 | Batch Status: 21120/60000 (35%) | Loss: 0.574549\n",
      "Train Epoch: 2 | Batch Status: 21760/60000 (36%) | Loss: 0.525862\n",
      "Train Epoch: 2 | Batch Status: 22400/60000 (37%) | Loss: 0.664618\n",
      "Train Epoch: 2 | Batch Status: 23040/60000 (38%) | Loss: 0.630330\n",
      "Train Epoch: 2 | Batch Status: 23680/60000 (39%) | Loss: 0.682291\n",
      "Train Epoch: 2 | Batch Status: 24320/60000 (41%) | Loss: 0.932880\n",
      "Train Epoch: 2 | Batch Status: 24960/60000 (42%) | Loss: 0.525883\n",
      "Train Epoch: 2 | Batch Status: 25600/60000 (43%) | Loss: 0.737651\n",
      "Train Epoch: 2 | Batch Status: 26240/60000 (44%) | Loss: 0.687828\n",
      "Train Epoch: 2 | Batch Status: 26880/60000 (45%) | Loss: 0.464310\n",
      "Train Epoch: 2 | Batch Status: 27520/60000 (46%) | Loss: 0.352714\n",
      "Train Epoch: 2 | Batch Status: 28160/60000 (47%) | Loss: 0.554172\n",
      "Train Epoch: 2 | Batch Status: 28800/60000 (48%) | Loss: 0.730782\n",
      "Train Epoch: 2 | Batch Status: 29440/60000 (49%) | Loss: 0.510247\n",
      "Train Epoch: 2 | Batch Status: 30080/60000 (50%) | Loss: 0.490247\n",
      "Train Epoch: 2 | Batch Status: 30720/60000 (51%) | Loss: 0.874210\n",
      "Train Epoch: 2 | Batch Status: 31360/60000 (52%) | Loss: 0.533494\n",
      "Train Epoch: 2 | Batch Status: 32000/60000 (53%) | Loss: 0.522938\n",
      "Train Epoch: 2 | Batch Status: 32640/60000 (54%) | Loss: 0.458969\n",
      "Train Epoch: 2 | Batch Status: 33280/60000 (55%) | Loss: 0.658596\n",
      "Train Epoch: 2 | Batch Status: 33920/60000 (57%) | Loss: 0.388183\n",
      "Train Epoch: 2 | Batch Status: 34560/60000 (58%) | Loss: 0.555181\n",
      "Train Epoch: 2 | Batch Status: 35200/60000 (59%) | Loss: 0.457607\n",
      "Train Epoch: 2 | Batch Status: 35840/60000 (60%) | Loss: 0.609763\n",
      "Train Epoch: 2 | Batch Status: 36480/60000 (61%) | Loss: 0.506437\n",
      "Train Epoch: 2 | Batch Status: 37120/60000 (62%) | Loss: 0.722460\n",
      "Train Epoch: 2 | Batch Status: 37760/60000 (63%) | Loss: 0.585859\n",
      "Train Epoch: 2 | Batch Status: 38400/60000 (64%) | Loss: 0.586306\n",
      "Train Epoch: 2 | Batch Status: 39040/60000 (65%) | Loss: 0.519112\n",
      "Train Epoch: 2 | Batch Status: 39680/60000 (66%) | Loss: 0.725822\n",
      "Train Epoch: 2 | Batch Status: 40320/60000 (67%) | Loss: 0.634887\n",
      "Train Epoch: 2 | Batch Status: 40960/60000 (68%) | Loss: 0.450440\n",
      "Train Epoch: 2 | Batch Status: 41600/60000 (69%) | Loss: 0.565523\n",
      "Train Epoch: 2 | Batch Status: 42240/60000 (70%) | Loss: 0.470525\n",
      "Train Epoch: 2 | Batch Status: 42880/60000 (71%) | Loss: 0.549852\n",
      "Train Epoch: 2 | Batch Status: 43520/60000 (72%) | Loss: 0.506771\n",
      "Train Epoch: 2 | Batch Status: 44160/60000 (74%) | Loss: 0.525475\n",
      "Train Epoch: 2 | Batch Status: 44800/60000 (75%) | Loss: 0.575456\n",
      "Train Epoch: 2 | Batch Status: 45440/60000 (76%) | Loss: 0.325586\n",
      "Train Epoch: 2 | Batch Status: 46080/60000 (77%) | Loss: 0.463454\n",
      "Train Epoch: 2 | Batch Status: 46720/60000 (78%) | Loss: 0.435713\n",
      "Train Epoch: 2 | Batch Status: 47360/60000 (79%) | Loss: 0.670027\n",
      "Train Epoch: 2 | Batch Status: 48000/60000 (80%) | Loss: 0.507855\n",
      "Train Epoch: 2 | Batch Status: 48640/60000 (81%) | Loss: 0.561767\n",
      "Train Epoch: 2 | Batch Status: 49280/60000 (82%) | Loss: 0.504409\n",
      "Train Epoch: 2 | Batch Status: 49920/60000 (83%) | Loss: 0.466219\n",
      "Train Epoch: 2 | Batch Status: 50560/60000 (84%) | Loss: 0.534282\n",
      "Train Epoch: 2 | Batch Status: 51200/60000 (85%) | Loss: 0.545562\n",
      "Train Epoch: 2 | Batch Status: 51840/60000 (86%) | Loss: 0.504672\n",
      "Train Epoch: 2 | Batch Status: 52480/60000 (87%) | Loss: 0.392928\n",
      "Train Epoch: 2 | Batch Status: 53120/60000 (88%) | Loss: 0.391262\n",
      "Train Epoch: 2 | Batch Status: 53760/60000 (90%) | Loss: 0.397311\n",
      "Train Epoch: 2 | Batch Status: 54400/60000 (91%) | Loss: 0.759074\n",
      "Train Epoch: 2 | Batch Status: 55040/60000 (92%) | Loss: 0.414809\n",
      "Train Epoch: 2 | Batch Status: 55680/60000 (93%) | Loss: 0.443943\n",
      "Train Epoch: 2 | Batch Status: 56320/60000 (94%) | Loss: 0.530934\n",
      "Train Epoch: 2 | Batch Status: 56960/60000 (95%) | Loss: 0.484411\n",
      "Train Epoch: 2 | Batch Status: 57600/60000 (96%) | Loss: 0.612727\n",
      "Train Epoch: 2 | Batch Status: 58240/60000 (97%) | Loss: 0.633458\n",
      "Train Epoch: 2 | Batch Status: 58880/60000 (98%) | Loss: 0.424677\n",
      "Train Epoch: 2 | Batch Status: 59520/60000 (99%) | Loss: 0.521127\n",
      "Training time: 0m 17s\n",
      "===========================\n",
      "Test set: Average loss: 0.0070, Accuracy: 8713/10000 (87%)\n",
      "Testing time: 0m 18s\n",
      "Train Epoch: 3 | Batch Status: 0/60000 (0%) | Loss: 0.308393\n",
      "Train Epoch: 3 | Batch Status: 640/60000 (1%) | Loss: 0.339209\n",
      "Train Epoch: 3 | Batch Status: 1280/60000 (2%) | Loss: 0.349434\n",
      "Train Epoch: 3 | Batch Status: 1920/60000 (3%) | Loss: 0.474918\n",
      "Train Epoch: 3 | Batch Status: 2560/60000 (4%) | Loss: 0.434632\n",
      "Train Epoch: 3 | Batch Status: 3200/60000 (5%) | Loss: 0.366179\n",
      "Train Epoch: 3 | Batch Status: 3840/60000 (6%) | Loss: 0.280989\n",
      "Train Epoch: 3 | Batch Status: 4480/60000 (7%) | Loss: 0.594266\n",
      "Train Epoch: 3 | Batch Status: 5120/60000 (9%) | Loss: 0.447442\n",
      "Train Epoch: 3 | Batch Status: 5760/60000 (10%) | Loss: 0.433302\n",
      "Train Epoch: 3 | Batch Status: 6400/60000 (11%) | Loss: 0.396595\n",
      "Train Epoch: 3 | Batch Status: 7040/60000 (12%) | Loss: 0.560149\n",
      "Train Epoch: 3 | Batch Status: 7680/60000 (13%) | Loss: 0.530158\n",
      "Train Epoch: 3 | Batch Status: 8320/60000 (14%) | Loss: 0.537136\n",
      "Train Epoch: 3 | Batch Status: 8960/60000 (15%) | Loss: 0.627687\n",
      "Train Epoch: 3 | Batch Status: 9600/60000 (16%) | Loss: 0.526978\n",
      "Train Epoch: 3 | Batch Status: 10240/60000 (17%) | Loss: 0.442885\n",
      "Train Epoch: 3 | Batch Status: 10880/60000 (18%) | Loss: 0.405370\n",
      "Train Epoch: 3 | Batch Status: 11520/60000 (19%) | Loss: 0.595154\n",
      "Train Epoch: 3 | Batch Status: 12160/60000 (20%) | Loss: 0.293388\n",
      "Train Epoch: 3 | Batch Status: 12800/60000 (21%) | Loss: 0.450532\n",
      "Train Epoch: 3 | Batch Status: 13440/60000 (22%) | Loss: 0.398448\n",
      "Train Epoch: 3 | Batch Status: 14080/60000 (23%) | Loss: 0.410603\n",
      "Train Epoch: 3 | Batch Status: 14720/60000 (25%) | Loss: 0.435954\n",
      "Train Epoch: 3 | Batch Status: 15360/60000 (26%) | Loss: 0.275513\n",
      "Train Epoch: 3 | Batch Status: 16000/60000 (27%) | Loss: 0.312423\n",
      "Train Epoch: 3 | Batch Status: 16640/60000 (28%) | Loss: 0.363248\n",
      "Train Epoch: 3 | Batch Status: 17280/60000 (29%) | Loss: 0.426100\n",
      "Train Epoch: 3 | Batch Status: 17920/60000 (30%) | Loss: 0.297279\n",
      "Train Epoch: 3 | Batch Status: 18560/60000 (31%) | Loss: 0.381707\n",
      "Train Epoch: 3 | Batch Status: 19200/60000 (32%) | Loss: 0.614105\n",
      "Train Epoch: 3 | Batch Status: 19840/60000 (33%) | Loss: 0.498860\n",
      "Train Epoch: 3 | Batch Status: 20480/60000 (34%) | Loss: 0.273768\n",
      "Train Epoch: 3 | Batch Status: 21120/60000 (35%) | Loss: 0.504349\n",
      "Train Epoch: 3 | Batch Status: 21760/60000 (36%) | Loss: 0.296288\n",
      "Train Epoch: 3 | Batch Status: 22400/60000 (37%) | Loss: 0.385610\n",
      "Train Epoch: 3 | Batch Status: 23040/60000 (38%) | Loss: 0.322900\n",
      "Train Epoch: 3 | Batch Status: 23680/60000 (39%) | Loss: 0.579056\n",
      "Train Epoch: 3 | Batch Status: 24320/60000 (41%) | Loss: 0.663360\n",
      "Train Epoch: 3 | Batch Status: 24960/60000 (42%) | Loss: 0.365734\n",
      "Train Epoch: 3 | Batch Status: 25600/60000 (43%) | Loss: 0.347562\n",
      "Train Epoch: 3 | Batch Status: 26240/60000 (44%) | Loss: 0.275675\n",
      "Train Epoch: 3 | Batch Status: 26880/60000 (45%) | Loss: 0.361530\n",
      "Train Epoch: 3 | Batch Status: 27520/60000 (46%) | Loss: 0.322789\n",
      "Train Epoch: 3 | Batch Status: 28160/60000 (47%) | Loss: 0.261119\n",
      "Train Epoch: 3 | Batch Status: 28800/60000 (48%) | Loss: 0.308264\n",
      "Train Epoch: 3 | Batch Status: 29440/60000 (49%) | Loss: 0.496033\n",
      "Train Epoch: 3 | Batch Status: 30080/60000 (50%) | Loss: 0.246386\n",
      "Train Epoch: 3 | Batch Status: 30720/60000 (51%) | Loss: 0.432094\n",
      "Train Epoch: 3 | Batch Status: 31360/60000 (52%) | Loss: 0.587449\n",
      "Train Epoch: 3 | Batch Status: 32000/60000 (53%) | Loss: 0.447175\n",
      "Train Epoch: 3 | Batch Status: 32640/60000 (54%) | Loss: 0.454572\n",
      "Train Epoch: 3 | Batch Status: 33280/60000 (55%) | Loss: 0.251508\n",
      "Train Epoch: 3 | Batch Status: 33920/60000 (57%) | Loss: 0.345810\n",
      "Train Epoch: 3 | Batch Status: 34560/60000 (58%) | Loss: 0.463206\n",
      "Train Epoch: 3 | Batch Status: 35200/60000 (59%) | Loss: 0.468387\n",
      "Train Epoch: 3 | Batch Status: 35840/60000 (60%) | Loss: 0.497853\n",
      "Train Epoch: 3 | Batch Status: 36480/60000 (61%) | Loss: 0.295839\n",
      "Train Epoch: 3 | Batch Status: 37120/60000 (62%) | Loss: 0.215786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 | Batch Status: 37760/60000 (63%) | Loss: 0.398199\n",
      "Train Epoch: 3 | Batch Status: 38400/60000 (64%) | Loss: 0.470699\n",
      "Train Epoch: 3 | Batch Status: 39040/60000 (65%) | Loss: 0.246517\n",
      "Train Epoch: 3 | Batch Status: 39680/60000 (66%) | Loss: 0.435483\n",
      "Train Epoch: 3 | Batch Status: 40320/60000 (67%) | Loss: 0.436764\n",
      "Train Epoch: 3 | Batch Status: 40960/60000 (68%) | Loss: 0.377630\n",
      "Train Epoch: 3 | Batch Status: 41600/60000 (69%) | Loss: 0.507303\n",
      "Train Epoch: 3 | Batch Status: 42240/60000 (70%) | Loss: 0.572427\n",
      "Train Epoch: 3 | Batch Status: 42880/60000 (71%) | Loss: 0.351430\n",
      "Train Epoch: 3 | Batch Status: 43520/60000 (72%) | Loss: 0.366165\n",
      "Train Epoch: 3 | Batch Status: 44160/60000 (74%) | Loss: 0.213867\n",
      "Train Epoch: 3 | Batch Status: 44800/60000 (75%) | Loss: 0.522221\n",
      "Train Epoch: 3 | Batch Status: 45440/60000 (76%) | Loss: 0.416126\n",
      "Train Epoch: 3 | Batch Status: 46080/60000 (77%) | Loss: 0.532777\n",
      "Train Epoch: 3 | Batch Status: 46720/60000 (78%) | Loss: 0.240879\n",
      "Train Epoch: 3 | Batch Status: 47360/60000 (79%) | Loss: 0.644656\n",
      "Train Epoch: 3 | Batch Status: 48000/60000 (80%) | Loss: 0.389664\n",
      "Train Epoch: 3 | Batch Status: 48640/60000 (81%) | Loss: 0.154149\n",
      "Train Epoch: 3 | Batch Status: 49280/60000 (82%) | Loss: 0.258793\n",
      "Train Epoch: 3 | Batch Status: 49920/60000 (83%) | Loss: 0.311784\n",
      "Train Epoch: 3 | Batch Status: 50560/60000 (84%) | Loss: 0.274885\n",
      "Train Epoch: 3 | Batch Status: 51200/60000 (85%) | Loss: 0.245282\n",
      "Train Epoch: 3 | Batch Status: 51840/60000 (86%) | Loss: 0.312296\n",
      "Train Epoch: 3 | Batch Status: 52480/60000 (87%) | Loss: 0.320630\n",
      "Train Epoch: 3 | Batch Status: 53120/60000 (88%) | Loss: 0.493633\n",
      "Train Epoch: 3 | Batch Status: 53760/60000 (90%) | Loss: 0.221774\n",
      "Train Epoch: 3 | Batch Status: 54400/60000 (91%) | Loss: 0.256808\n",
      "Train Epoch: 3 | Batch Status: 55040/60000 (92%) | Loss: 0.167397\n",
      "Train Epoch: 3 | Batch Status: 55680/60000 (93%) | Loss: 0.245967\n",
      "Train Epoch: 3 | Batch Status: 56320/60000 (94%) | Loss: 0.381078\n",
      "Train Epoch: 3 | Batch Status: 56960/60000 (95%) | Loss: 0.233611\n",
      "Train Epoch: 3 | Batch Status: 57600/60000 (96%) | Loss: 0.315357\n",
      "Train Epoch: 3 | Batch Status: 58240/60000 (97%) | Loss: 0.219661\n",
      "Train Epoch: 3 | Batch Status: 58880/60000 (98%) | Loss: 0.202335\n",
      "Train Epoch: 3 | Batch Status: 59520/60000 (99%) | Loss: 0.577356\n",
      "Training time: 0m 15s\n",
      "===========================\n",
      "Test set: Average loss: 0.0048, Accuracy: 9112/10000 (91%)\n",
      "Testing time: 0m 16s\n",
      "Train Epoch: 4 | Batch Status: 0/60000 (0%) | Loss: 0.259843\n",
      "Train Epoch: 4 | Batch Status: 640/60000 (1%) | Loss: 0.282650\n",
      "Train Epoch: 4 | Batch Status: 1280/60000 (2%) | Loss: 0.397139\n",
      "Train Epoch: 4 | Batch Status: 1920/60000 (3%) | Loss: 0.224579\n",
      "Train Epoch: 4 | Batch Status: 2560/60000 (4%) | Loss: 0.256427\n",
      "Train Epoch: 4 | Batch Status: 3200/60000 (5%) | Loss: 0.257691\n",
      "Train Epoch: 4 | Batch Status: 3840/60000 (6%) | Loss: 0.516016\n",
      "Train Epoch: 4 | Batch Status: 4480/60000 (7%) | Loss: 0.262366\n",
      "Train Epoch: 4 | Batch Status: 5120/60000 (9%) | Loss: 0.333395\n",
      "Train Epoch: 4 | Batch Status: 5760/60000 (10%) | Loss: 0.186130\n",
      "Train Epoch: 4 | Batch Status: 6400/60000 (11%) | Loss: 0.381887\n",
      "Train Epoch: 4 | Batch Status: 7040/60000 (12%) | Loss: 0.537708\n",
      "Train Epoch: 4 | Batch Status: 7680/60000 (13%) | Loss: 0.208655\n",
      "Train Epoch: 4 | Batch Status: 8320/60000 (14%) | Loss: 0.303325\n",
      "Train Epoch: 4 | Batch Status: 8960/60000 (15%) | Loss: 0.550318\n",
      "Train Epoch: 4 | Batch Status: 9600/60000 (16%) | Loss: 0.439392\n",
      "Train Epoch: 4 | Batch Status: 10240/60000 (17%) | Loss: 0.332128\n",
      "Train Epoch: 4 | Batch Status: 10880/60000 (18%) | Loss: 0.111873\n",
      "Train Epoch: 4 | Batch Status: 11520/60000 (19%) | Loss: 0.175373\n",
      "Train Epoch: 4 | Batch Status: 12160/60000 (20%) | Loss: 0.190141\n",
      "Train Epoch: 4 | Batch Status: 12800/60000 (21%) | Loss: 0.451393\n",
      "Train Epoch: 4 | Batch Status: 13440/60000 (22%) | Loss: 0.270062\n",
      "Train Epoch: 4 | Batch Status: 14080/60000 (23%) | Loss: 0.173683\n",
      "Train Epoch: 4 | Batch Status: 14720/60000 (25%) | Loss: 0.242627\n",
      "Train Epoch: 4 | Batch Status: 15360/60000 (26%) | Loss: 0.228171\n",
      "Train Epoch: 4 | Batch Status: 16000/60000 (27%) | Loss: 0.285106\n",
      "Train Epoch: 4 | Batch Status: 16640/60000 (28%) | Loss: 0.253574\n",
      "Train Epoch: 4 | Batch Status: 17280/60000 (29%) | Loss: 0.160724\n",
      "Train Epoch: 4 | Batch Status: 17920/60000 (30%) | Loss: 0.366963\n",
      "Train Epoch: 4 | Batch Status: 18560/60000 (31%) | Loss: 0.443723\n",
      "Train Epoch: 4 | Batch Status: 19200/60000 (32%) | Loss: 0.278426\n",
      "Train Epoch: 4 | Batch Status: 19840/60000 (33%) | Loss: 0.324673\n",
      "Train Epoch: 4 | Batch Status: 20480/60000 (34%) | Loss: 0.133046\n",
      "Train Epoch: 4 | Batch Status: 21120/60000 (35%) | Loss: 0.213866\n",
      "Train Epoch: 4 | Batch Status: 21760/60000 (36%) | Loss: 0.231682\n",
      "Train Epoch: 4 | Batch Status: 22400/60000 (37%) | Loss: 0.324665\n",
      "Train Epoch: 4 | Batch Status: 23040/60000 (38%) | Loss: 0.437820\n",
      "Train Epoch: 4 | Batch Status: 23680/60000 (39%) | Loss: 0.283454\n",
      "Train Epoch: 4 | Batch Status: 24320/60000 (41%) | Loss: 0.352910\n",
      "Train Epoch: 4 | Batch Status: 24960/60000 (42%) | Loss: 0.201334\n",
      "Train Epoch: 4 | Batch Status: 25600/60000 (43%) | Loss: 0.203041\n",
      "Train Epoch: 4 | Batch Status: 26240/60000 (44%) | Loss: 0.139489\n",
      "Train Epoch: 4 | Batch Status: 26880/60000 (45%) | Loss: 0.212424\n",
      "Train Epoch: 4 | Batch Status: 27520/60000 (46%) | Loss: 0.214240\n",
      "Train Epoch: 4 | Batch Status: 28160/60000 (47%) | Loss: 0.251562\n",
      "Train Epoch: 4 | Batch Status: 28800/60000 (48%) | Loss: 0.317525\n",
      "Train Epoch: 4 | Batch Status: 29440/60000 (49%) | Loss: 0.174740\n",
      "Train Epoch: 4 | Batch Status: 30080/60000 (50%) | Loss: 0.229321\n",
      "Train Epoch: 4 | Batch Status: 30720/60000 (51%) | Loss: 0.212321\n",
      "Train Epoch: 4 | Batch Status: 31360/60000 (52%) | Loss: 0.188353\n",
      "Train Epoch: 4 | Batch Status: 32000/60000 (53%) | Loss: 0.204270\n",
      "Train Epoch: 4 | Batch Status: 32640/60000 (54%) | Loss: 0.494234\n",
      "Train Epoch: 4 | Batch Status: 33280/60000 (55%) | Loss: 0.109914\n",
      "Train Epoch: 4 | Batch Status: 33920/60000 (57%) | Loss: 0.348319\n",
      "Train Epoch: 4 | Batch Status: 34560/60000 (58%) | Loss: 0.229513\n",
      "Train Epoch: 4 | Batch Status: 35200/60000 (59%) | Loss: 0.110313\n",
      "Train Epoch: 4 | Batch Status: 35840/60000 (60%) | Loss: 0.433682\n",
      "Train Epoch: 4 | Batch Status: 36480/60000 (61%) | Loss: 0.434138\n",
      "Train Epoch: 4 | Batch Status: 37120/60000 (62%) | Loss: 0.399789\n",
      "Train Epoch: 4 | Batch Status: 37760/60000 (63%) | Loss: 0.203285\n",
      "Train Epoch: 4 | Batch Status: 38400/60000 (64%) | Loss: 0.483689\n",
      "Train Epoch: 4 | Batch Status: 39040/60000 (65%) | Loss: 0.416595\n",
      "Train Epoch: 4 | Batch Status: 39680/60000 (66%) | Loss: 0.253797\n",
      "Train Epoch: 4 | Batch Status: 40320/60000 (67%) | Loss: 0.177474\n",
      "Train Epoch: 4 | Batch Status: 40960/60000 (68%) | Loss: 0.210302\n",
      "Train Epoch: 4 | Batch Status: 41600/60000 (69%) | Loss: 0.224647\n",
      "Train Epoch: 4 | Batch Status: 42240/60000 (70%) | Loss: 0.143057\n",
      "Train Epoch: 4 | Batch Status: 42880/60000 (71%) | Loss: 0.152209\n",
      "Train Epoch: 4 | Batch Status: 43520/60000 (72%) | Loss: 0.317804\n",
      "Train Epoch: 4 | Batch Status: 44160/60000 (74%) | Loss: 0.520035\n",
      "Train Epoch: 4 | Batch Status: 44800/60000 (75%) | Loss: 0.141432\n",
      "Train Epoch: 4 | Batch Status: 45440/60000 (76%) | Loss: 0.269756\n",
      "Train Epoch: 4 | Batch Status: 46080/60000 (77%) | Loss: 0.196731\n",
      "Train Epoch: 4 | Batch Status: 46720/60000 (78%) | Loss: 0.170005\n",
      "Train Epoch: 4 | Batch Status: 47360/60000 (79%) | Loss: 0.227547\n",
      "Train Epoch: 4 | Batch Status: 48000/60000 (80%) | Loss: 0.231323\n",
      "Train Epoch: 4 | Batch Status: 48640/60000 (81%) | Loss: 0.221461\n",
      "Train Epoch: 4 | Batch Status: 49280/60000 (82%) | Loss: 0.122729\n",
      "Train Epoch: 4 | Batch Status: 49920/60000 (83%) | Loss: 0.295215\n",
      "Train Epoch: 4 | Batch Status: 50560/60000 (84%) | Loss: 0.150590\n",
      "Train Epoch: 4 | Batch Status: 51200/60000 (85%) | Loss: 0.204211\n",
      "Train Epoch: 4 | Batch Status: 51840/60000 (86%) | Loss: 0.120862\n",
      "Train Epoch: 4 | Batch Status: 52480/60000 (87%) | Loss: 0.201109\n",
      "Train Epoch: 4 | Batch Status: 53120/60000 (88%) | Loss: 0.425889\n",
      "Train Epoch: 4 | Batch Status: 53760/60000 (90%) | Loss: 0.209098\n",
      "Train Epoch: 4 | Batch Status: 54400/60000 (91%) | Loss: 0.339707\n",
      "Train Epoch: 4 | Batch Status: 55040/60000 (92%) | Loss: 0.143872\n",
      "Train Epoch: 4 | Batch Status: 55680/60000 (93%) | Loss: 0.151907\n",
      "Train Epoch: 4 | Batch Status: 56320/60000 (94%) | Loss: 0.175285\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4 | Batch Status: 56960/60000 (95%) | Loss: 0.241650\n",
      "Train Epoch: 4 | Batch Status: 57600/60000 (96%) | Loss: 0.190648\n",
      "Train Epoch: 4 | Batch Status: 58240/60000 (97%) | Loss: 0.109561\n",
      "Train Epoch: 4 | Batch Status: 58880/60000 (98%) | Loss: 0.587798\n",
      "Train Epoch: 4 | Batch Status: 59520/60000 (99%) | Loss: 0.242309\n",
      "Training time: 0m 16s\n",
      "===========================\n",
      "Test set: Average loss: 0.0040, Accuracy: 9219/10000 (92%)\n",
      "Testing time: 0m 17s\n",
      "Train Epoch: 5 | Batch Status: 0/60000 (0%) | Loss: 0.257158\n",
      "Train Epoch: 5 | Batch Status: 640/60000 (1%) | Loss: 0.242387\n",
      "Train Epoch: 5 | Batch Status: 1280/60000 (2%) | Loss: 0.158387\n",
      "Train Epoch: 5 | Batch Status: 1920/60000 (3%) | Loss: 0.520817\n",
      "Train Epoch: 5 | Batch Status: 2560/60000 (4%) | Loss: 0.323188\n",
      "Train Epoch: 5 | Batch Status: 3200/60000 (5%) | Loss: 0.358452\n",
      "Train Epoch: 5 | Batch Status: 3840/60000 (6%) | Loss: 0.212551\n",
      "Train Epoch: 5 | Batch Status: 4480/60000 (7%) | Loss: 0.185032\n",
      "Train Epoch: 5 | Batch Status: 5120/60000 (9%) | Loss: 0.144659\n",
      "Train Epoch: 5 | Batch Status: 5760/60000 (10%) | Loss: 0.240017\n",
      "Train Epoch: 5 | Batch Status: 6400/60000 (11%) | Loss: 0.399336\n",
      "Train Epoch: 5 | Batch Status: 7040/60000 (12%) | Loss: 0.202147\n",
      "Train Epoch: 5 | Batch Status: 7680/60000 (13%) | Loss: 0.113142\n",
      "Train Epoch: 5 | Batch Status: 8320/60000 (14%) | Loss: 0.204193\n",
      "Train Epoch: 5 | Batch Status: 8960/60000 (15%) | Loss: 0.128335\n",
      "Train Epoch: 5 | Batch Status: 9600/60000 (16%) | Loss: 0.147998\n",
      "Train Epoch: 5 | Batch Status: 10240/60000 (17%) | Loss: 0.095832\n",
      "Train Epoch: 5 | Batch Status: 10880/60000 (18%) | Loss: 0.225852\n",
      "Train Epoch: 5 | Batch Status: 11520/60000 (19%) | Loss: 0.160125\n",
      "Train Epoch: 5 | Batch Status: 12160/60000 (20%) | Loss: 0.235376\n",
      "Train Epoch: 5 | Batch Status: 12800/60000 (21%) | Loss: 0.305133\n",
      "Train Epoch: 5 | Batch Status: 13440/60000 (22%) | Loss: 0.418161\n",
      "Train Epoch: 5 | Batch Status: 14080/60000 (23%) | Loss: 0.188252\n",
      "Train Epoch: 5 | Batch Status: 14720/60000 (25%) | Loss: 0.117653\n",
      "Train Epoch: 5 | Batch Status: 15360/60000 (26%) | Loss: 0.414259\n",
      "Train Epoch: 5 | Batch Status: 16000/60000 (27%) | Loss: 0.380076\n",
      "Train Epoch: 5 | Batch Status: 16640/60000 (28%) | Loss: 0.175129\n",
      "Train Epoch: 5 | Batch Status: 17280/60000 (29%) | Loss: 0.177721\n",
      "Train Epoch: 5 | Batch Status: 17920/60000 (30%) | Loss: 0.245538\n",
      "Train Epoch: 5 | Batch Status: 18560/60000 (31%) | Loss: 0.140225\n",
      "Train Epoch: 5 | Batch Status: 19200/60000 (32%) | Loss: 0.231063\n",
      "Train Epoch: 5 | Batch Status: 19840/60000 (33%) | Loss: 0.330478\n",
      "Train Epoch: 5 | Batch Status: 20480/60000 (34%) | Loss: 0.222442\n",
      "Train Epoch: 5 | Batch Status: 21120/60000 (35%) | Loss: 0.245954\n",
      "Train Epoch: 5 | Batch Status: 21760/60000 (36%) | Loss: 0.178490\n",
      "Train Epoch: 5 | Batch Status: 22400/60000 (37%) | Loss: 0.260648\n",
      "Train Epoch: 5 | Batch Status: 23040/60000 (38%) | Loss: 0.172903\n",
      "Train Epoch: 5 | Batch Status: 23680/60000 (39%) | Loss: 0.121847\n",
      "Train Epoch: 5 | Batch Status: 24320/60000 (41%) | Loss: 0.215254\n",
      "Train Epoch: 5 | Batch Status: 24960/60000 (42%) | Loss: 0.104464\n",
      "Train Epoch: 5 | Batch Status: 25600/60000 (43%) | Loss: 0.219785\n",
      "Train Epoch: 5 | Batch Status: 26240/60000 (44%) | Loss: 0.376277\n",
      "Train Epoch: 5 | Batch Status: 26880/60000 (45%) | Loss: 0.420706\n",
      "Train Epoch: 5 | Batch Status: 27520/60000 (46%) | Loss: 0.158366\n",
      "Train Epoch: 5 | Batch Status: 28160/60000 (47%) | Loss: 0.281040\n",
      "Train Epoch: 5 | Batch Status: 28800/60000 (48%) | Loss: 0.140868\n",
      "Train Epoch: 5 | Batch Status: 29440/60000 (49%) | Loss: 0.175640\n",
      "Train Epoch: 5 | Batch Status: 30080/60000 (50%) | Loss: 0.092398\n",
      "Train Epoch: 5 | Batch Status: 30720/60000 (51%) | Loss: 0.126987\n",
      "Train Epoch: 5 | Batch Status: 31360/60000 (52%) | Loss: 0.097584\n",
      "Train Epoch: 5 | Batch Status: 32000/60000 (53%) | Loss: 0.345476\n",
      "Train Epoch: 5 | Batch Status: 32640/60000 (54%) | Loss: 0.258415\n",
      "Train Epoch: 5 | Batch Status: 33280/60000 (55%) | Loss: 0.184692\n",
      "Train Epoch: 5 | Batch Status: 33920/60000 (57%) | Loss: 0.118875\n",
      "Train Epoch: 5 | Batch Status: 34560/60000 (58%) | Loss: 0.119167\n",
      "Train Epoch: 5 | Batch Status: 35200/60000 (59%) | Loss: 0.150479\n",
      "Train Epoch: 5 | Batch Status: 35840/60000 (60%) | Loss: 0.137871\n",
      "Train Epoch: 5 | Batch Status: 36480/60000 (61%) | Loss: 0.308851\n",
      "Train Epoch: 5 | Batch Status: 37120/60000 (62%) | Loss: 0.109139\n",
      "Train Epoch: 5 | Batch Status: 37760/60000 (63%) | Loss: 0.198869\n",
      "Train Epoch: 5 | Batch Status: 38400/60000 (64%) | Loss: 0.131099\n",
      "Train Epoch: 5 | Batch Status: 39040/60000 (65%) | Loss: 0.248843\n",
      "Train Epoch: 5 | Batch Status: 39680/60000 (66%) | Loss: 0.110294\n",
      "Train Epoch: 5 | Batch Status: 40320/60000 (67%) | Loss: 0.158504\n",
      "Train Epoch: 5 | Batch Status: 40960/60000 (68%) | Loss: 0.142649\n",
      "Train Epoch: 5 | Batch Status: 41600/60000 (69%) | Loss: 0.145076\n",
      "Train Epoch: 5 | Batch Status: 42240/60000 (70%) | Loss: 0.156015\n",
      "Train Epoch: 5 | Batch Status: 42880/60000 (71%) | Loss: 0.185970\n",
      "Train Epoch: 5 | Batch Status: 43520/60000 (72%) | Loss: 0.129985\n",
      "Train Epoch: 5 | Batch Status: 44160/60000 (74%) | Loss: 0.327065\n",
      "Train Epoch: 5 | Batch Status: 44800/60000 (75%) | Loss: 0.143430\n",
      "Train Epoch: 5 | Batch Status: 45440/60000 (76%) | Loss: 0.245682\n",
      "Train Epoch: 5 | Batch Status: 46080/60000 (77%) | Loss: 0.424277\n",
      "Train Epoch: 5 | Batch Status: 46720/60000 (78%) | Loss: 0.092205\n",
      "Train Epoch: 5 | Batch Status: 47360/60000 (79%) | Loss: 0.058691\n",
      "Train Epoch: 5 | Batch Status: 48000/60000 (80%) | Loss: 0.324112\n",
      "Train Epoch: 5 | Batch Status: 48640/60000 (81%) | Loss: 0.200770\n",
      "Train Epoch: 5 | Batch Status: 49280/60000 (82%) | Loss: 0.192139\n",
      "Train Epoch: 5 | Batch Status: 49920/60000 (83%) | Loss: 0.035939\n",
      "Train Epoch: 5 | Batch Status: 50560/60000 (84%) | Loss: 0.433999\n",
      "Train Epoch: 5 | Batch Status: 51200/60000 (85%) | Loss: 0.151663\n",
      "Train Epoch: 5 | Batch Status: 51840/60000 (86%) | Loss: 0.153619\n",
      "Train Epoch: 5 | Batch Status: 52480/60000 (87%) | Loss: 0.229692\n",
      "Train Epoch: 5 | Batch Status: 53120/60000 (88%) | Loss: 0.131599\n",
      "Train Epoch: 5 | Batch Status: 53760/60000 (90%) | Loss: 0.180495\n",
      "Train Epoch: 5 | Batch Status: 54400/60000 (91%) | Loss: 0.121745\n",
      "Train Epoch: 5 | Batch Status: 55040/60000 (92%) | Loss: 0.093365\n",
      "Train Epoch: 5 | Batch Status: 55680/60000 (93%) | Loss: 0.201282\n",
      "Train Epoch: 5 | Batch Status: 56320/60000 (94%) | Loss: 0.153555\n",
      "Train Epoch: 5 | Batch Status: 56960/60000 (95%) | Loss: 0.152282\n",
      "Train Epoch: 5 | Batch Status: 57600/60000 (96%) | Loss: 0.210346\n",
      "Train Epoch: 5 | Batch Status: 58240/60000 (97%) | Loss: 0.202687\n",
      "Train Epoch: 5 | Batch Status: 58880/60000 (98%) | Loss: 0.205832\n",
      "Train Epoch: 5 | Batch Status: 59520/60000 (99%) | Loss: 0.180659\n",
      "Training time: 0m 15s\n",
      "===========================\n",
      "Test set: Average loss: 0.0028, Accuracy: 9463/10000 (95%)\n",
      "Testing time: 0m 16s\n",
      "Train Epoch: 6 | Batch Status: 0/60000 (0%) | Loss: 0.163651\n",
      "Train Epoch: 6 | Batch Status: 640/60000 (1%) | Loss: 0.193103\n",
      "Train Epoch: 6 | Batch Status: 1280/60000 (2%) | Loss: 0.186396\n",
      "Train Epoch: 6 | Batch Status: 1920/60000 (3%) | Loss: 0.201249\n",
      "Train Epoch: 6 | Batch Status: 2560/60000 (4%) | Loss: 0.133015\n",
      "Train Epoch: 6 | Batch Status: 3200/60000 (5%) | Loss: 0.368136\n",
      "Train Epoch: 6 | Batch Status: 3840/60000 (6%) | Loss: 0.252937\n",
      "Train Epoch: 6 | Batch Status: 4480/60000 (7%) | Loss: 0.217659\n",
      "Train Epoch: 6 | Batch Status: 5120/60000 (9%) | Loss: 0.179282\n",
      "Train Epoch: 6 | Batch Status: 5760/60000 (10%) | Loss: 0.192976\n",
      "Train Epoch: 6 | Batch Status: 6400/60000 (11%) | Loss: 0.199249\n",
      "Train Epoch: 6 | Batch Status: 7040/60000 (12%) | Loss: 0.078261\n",
      "Train Epoch: 6 | Batch Status: 7680/60000 (13%) | Loss: 0.087661\n",
      "Train Epoch: 6 | Batch Status: 8320/60000 (14%) | Loss: 0.133653\n",
      "Train Epoch: 6 | Batch Status: 8960/60000 (15%) | Loss: 0.451863\n",
      "Train Epoch: 6 | Batch Status: 9600/60000 (16%) | Loss: 0.242123\n",
      "Train Epoch: 6 | Batch Status: 10240/60000 (17%) | Loss: 0.219290\n",
      "Train Epoch: 6 | Batch Status: 10880/60000 (18%) | Loss: 0.101624\n",
      "Train Epoch: 6 | Batch Status: 11520/60000 (19%) | Loss: 0.236291\n",
      "Train Epoch: 6 | Batch Status: 12160/60000 (20%) | Loss: 0.093093\n",
      "Train Epoch: 6 | Batch Status: 12800/60000 (21%) | Loss: 0.069783\n",
      "Train Epoch: 6 | Batch Status: 13440/60000 (22%) | Loss: 0.124706\n",
      "Train Epoch: 6 | Batch Status: 14080/60000 (23%) | Loss: 0.129925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6 | Batch Status: 14720/60000 (25%) | Loss: 0.109803\n",
      "Train Epoch: 6 | Batch Status: 15360/60000 (26%) | Loss: 0.148865\n",
      "Train Epoch: 6 | Batch Status: 16000/60000 (27%) | Loss: 0.157271\n",
      "Train Epoch: 6 | Batch Status: 16640/60000 (28%) | Loss: 0.240319\n",
      "Train Epoch: 6 | Batch Status: 17280/60000 (29%) | Loss: 0.112769\n",
      "Train Epoch: 6 | Batch Status: 17920/60000 (30%) | Loss: 0.148524\n",
      "Train Epoch: 6 | Batch Status: 18560/60000 (31%) | Loss: 0.127195\n",
      "Train Epoch: 6 | Batch Status: 19200/60000 (32%) | Loss: 0.258864\n",
      "Train Epoch: 6 | Batch Status: 19840/60000 (33%) | Loss: 0.152398\n",
      "Train Epoch: 6 | Batch Status: 20480/60000 (34%) | Loss: 0.185749\n",
      "Train Epoch: 6 | Batch Status: 21120/60000 (35%) | Loss: 0.122520\n",
      "Train Epoch: 6 | Batch Status: 21760/60000 (36%) | Loss: 0.131276\n",
      "Train Epoch: 6 | Batch Status: 22400/60000 (37%) | Loss: 0.061157\n",
      "Train Epoch: 6 | Batch Status: 23040/60000 (38%) | Loss: 0.128782\n",
      "Train Epoch: 6 | Batch Status: 23680/60000 (39%) | Loss: 0.150431\n",
      "Train Epoch: 6 | Batch Status: 24320/60000 (41%) | Loss: 0.421058\n",
      "Train Epoch: 6 | Batch Status: 24960/60000 (42%) | Loss: 0.067068\n",
      "Train Epoch: 6 | Batch Status: 25600/60000 (43%) | Loss: 0.114076\n",
      "Train Epoch: 6 | Batch Status: 26240/60000 (44%) | Loss: 0.186409\n",
      "Train Epoch: 6 | Batch Status: 26880/60000 (45%) | Loss: 0.171572\n",
      "Train Epoch: 6 | Batch Status: 27520/60000 (46%) | Loss: 0.156167\n",
      "Train Epoch: 6 | Batch Status: 28160/60000 (47%) | Loss: 0.204748\n",
      "Train Epoch: 6 | Batch Status: 28800/60000 (48%) | Loss: 0.194308\n",
      "Train Epoch: 6 | Batch Status: 29440/60000 (49%) | Loss: 0.142132\n",
      "Train Epoch: 6 | Batch Status: 30080/60000 (50%) | Loss: 0.245850\n",
      "Train Epoch: 6 | Batch Status: 30720/60000 (51%) | Loss: 0.475012\n",
      "Train Epoch: 6 | Batch Status: 31360/60000 (52%) | Loss: 0.102520\n",
      "Train Epoch: 6 | Batch Status: 32000/60000 (53%) | Loss: 0.145509\n",
      "Train Epoch: 6 | Batch Status: 32640/60000 (54%) | Loss: 0.088043\n",
      "Train Epoch: 6 | Batch Status: 33280/60000 (55%) | Loss: 0.093476\n",
      "Train Epoch: 6 | Batch Status: 33920/60000 (57%) | Loss: 0.090241\n",
      "Train Epoch: 6 | Batch Status: 34560/60000 (58%) | Loss: 0.130835\n",
      "Train Epoch: 6 | Batch Status: 35200/60000 (59%) | Loss: 0.216214\n",
      "Train Epoch: 6 | Batch Status: 35840/60000 (60%) | Loss: 0.089923\n",
      "Train Epoch: 6 | Batch Status: 36480/60000 (61%) | Loss: 0.131304\n",
      "Train Epoch: 6 | Batch Status: 37120/60000 (62%) | Loss: 0.299800\n",
      "Train Epoch: 6 | Batch Status: 37760/60000 (63%) | Loss: 0.169644\n",
      "Train Epoch: 6 | Batch Status: 38400/60000 (64%) | Loss: 0.118151\n",
      "Train Epoch: 6 | Batch Status: 39040/60000 (65%) | Loss: 0.228652\n",
      "Train Epoch: 6 | Batch Status: 39680/60000 (66%) | Loss: 0.124804\n",
      "Train Epoch: 6 | Batch Status: 40320/60000 (67%) | Loss: 0.179527\n",
      "Train Epoch: 6 | Batch Status: 40960/60000 (68%) | Loss: 0.058650\n",
      "Train Epoch: 6 | Batch Status: 41600/60000 (69%) | Loss: 0.059078\n",
      "Train Epoch: 6 | Batch Status: 42240/60000 (70%) | Loss: 0.150976\n",
      "Train Epoch: 6 | Batch Status: 42880/60000 (71%) | Loss: 0.072461\n",
      "Train Epoch: 6 | Batch Status: 43520/60000 (72%) | Loss: 0.238550\n",
      "Train Epoch: 6 | Batch Status: 44160/60000 (74%) | Loss: 0.086829\n",
      "Train Epoch: 6 | Batch Status: 44800/60000 (75%) | Loss: 0.169440\n",
      "Train Epoch: 6 | Batch Status: 45440/60000 (76%) | Loss: 0.291087\n",
      "Train Epoch: 6 | Batch Status: 46080/60000 (77%) | Loss: 0.078749\n",
      "Train Epoch: 6 | Batch Status: 46720/60000 (78%) | Loss: 0.388279\n",
      "Train Epoch: 6 | Batch Status: 47360/60000 (79%) | Loss: 0.103297\n",
      "Train Epoch: 6 | Batch Status: 48000/60000 (80%) | Loss: 0.057097\n",
      "Train Epoch: 6 | Batch Status: 48640/60000 (81%) | Loss: 0.068734\n",
      "Train Epoch: 6 | Batch Status: 49280/60000 (82%) | Loss: 0.160375\n",
      "Train Epoch: 6 | Batch Status: 49920/60000 (83%) | Loss: 0.138726\n",
      "Train Epoch: 6 | Batch Status: 50560/60000 (84%) | Loss: 0.193196\n",
      "Train Epoch: 6 | Batch Status: 51200/60000 (85%) | Loss: 0.055811\n",
      "Train Epoch: 6 | Batch Status: 51840/60000 (86%) | Loss: 0.157868\n",
      "Train Epoch: 6 | Batch Status: 52480/60000 (87%) | Loss: 0.178428\n",
      "Train Epoch: 6 | Batch Status: 53120/60000 (88%) | Loss: 0.184231\n",
      "Train Epoch: 6 | Batch Status: 53760/60000 (90%) | Loss: 0.238281\n",
      "Train Epoch: 6 | Batch Status: 54400/60000 (91%) | Loss: 0.201870\n",
      "Train Epoch: 6 | Batch Status: 55040/60000 (92%) | Loss: 0.132403\n",
      "Train Epoch: 6 | Batch Status: 55680/60000 (93%) | Loss: 0.180144\n",
      "Train Epoch: 6 | Batch Status: 56320/60000 (94%) | Loss: 0.130879\n",
      "Train Epoch: 6 | Batch Status: 56960/60000 (95%) | Loss: 0.117664\n",
      "Train Epoch: 6 | Batch Status: 57600/60000 (96%) | Loss: 0.091652\n",
      "Train Epoch: 6 | Batch Status: 58240/60000 (97%) | Loss: 0.249281\n",
      "Train Epoch: 6 | Batch Status: 58880/60000 (98%) | Loss: 0.192546\n",
      "Train Epoch: 6 | Batch Status: 59520/60000 (99%) | Loss: 0.072212\n",
      "Training time: 0m 18s\n",
      "===========================\n",
      "Test set: Average loss: 0.0026, Accuracy: 9490/10000 (95%)\n",
      "Testing time: 0m 20s\n",
      "Train Epoch: 7 | Batch Status: 0/60000 (0%) | Loss: 0.167888\n",
      "Train Epoch: 7 | Batch Status: 640/60000 (1%) | Loss: 0.297391\n",
      "Train Epoch: 7 | Batch Status: 1280/60000 (2%) | Loss: 0.040525\n",
      "Train Epoch: 7 | Batch Status: 1920/60000 (3%) | Loss: 0.032280\n",
      "Train Epoch: 7 | Batch Status: 2560/60000 (4%) | Loss: 0.155960\n",
      "Train Epoch: 7 | Batch Status: 3200/60000 (5%) | Loss: 0.108306\n",
      "Train Epoch: 7 | Batch Status: 3840/60000 (6%) | Loss: 0.157740\n",
      "Train Epoch: 7 | Batch Status: 4480/60000 (7%) | Loss: 0.134599\n",
      "Train Epoch: 7 | Batch Status: 5120/60000 (9%) | Loss: 0.166149\n",
      "Train Epoch: 7 | Batch Status: 5760/60000 (10%) | Loss: 0.192419\n",
      "Train Epoch: 7 | Batch Status: 6400/60000 (11%) | Loss: 0.045811\n",
      "Train Epoch: 7 | Batch Status: 7040/60000 (12%) | Loss: 0.176818\n",
      "Train Epoch: 7 | Batch Status: 7680/60000 (13%) | Loss: 0.171333\n",
      "Train Epoch: 7 | Batch Status: 8320/60000 (14%) | Loss: 0.123873\n",
      "Train Epoch: 7 | Batch Status: 8960/60000 (15%) | Loss: 0.103250\n",
      "Train Epoch: 7 | Batch Status: 9600/60000 (16%) | Loss: 0.154379\n",
      "Train Epoch: 7 | Batch Status: 10240/60000 (17%) | Loss: 0.050185\n",
      "Train Epoch: 7 | Batch Status: 10880/60000 (18%) | Loss: 0.101054\n",
      "Train Epoch: 7 | Batch Status: 11520/60000 (19%) | Loss: 0.063749\n",
      "Train Epoch: 7 | Batch Status: 12160/60000 (20%) | Loss: 0.057717\n",
      "Train Epoch: 7 | Batch Status: 12800/60000 (21%) | Loss: 0.194178\n",
      "Train Epoch: 7 | Batch Status: 13440/60000 (22%) | Loss: 0.188046\n",
      "Train Epoch: 7 | Batch Status: 14080/60000 (23%) | Loss: 0.032875\n",
      "Train Epoch: 7 | Batch Status: 14720/60000 (25%) | Loss: 0.064141\n",
      "Train Epoch: 7 | Batch Status: 15360/60000 (26%) | Loss: 0.176010\n",
      "Train Epoch: 7 | Batch Status: 16000/60000 (27%) | Loss: 0.097457\n",
      "Train Epoch: 7 | Batch Status: 16640/60000 (28%) | Loss: 0.147452\n",
      "Train Epoch: 7 | Batch Status: 17280/60000 (29%) | Loss: 0.098614\n",
      "Train Epoch: 7 | Batch Status: 17920/60000 (30%) | Loss: 0.096788\n",
      "Train Epoch: 7 | Batch Status: 18560/60000 (31%) | Loss: 0.181845\n",
      "Train Epoch: 7 | Batch Status: 19200/60000 (32%) | Loss: 0.146947\n",
      "Train Epoch: 7 | Batch Status: 19840/60000 (33%) | Loss: 0.114552\n",
      "Train Epoch: 7 | Batch Status: 20480/60000 (34%) | Loss: 0.219332\n",
      "Train Epoch: 7 | Batch Status: 21120/60000 (35%) | Loss: 0.058523\n",
      "Train Epoch: 7 | Batch Status: 21760/60000 (36%) | Loss: 0.078491\n",
      "Train Epoch: 7 | Batch Status: 22400/60000 (37%) | Loss: 0.102008\n",
      "Train Epoch: 7 | Batch Status: 23040/60000 (38%) | Loss: 0.109539\n",
      "Train Epoch: 7 | Batch Status: 23680/60000 (39%) | Loss: 0.116478\n",
      "Train Epoch: 7 | Batch Status: 24320/60000 (41%) | Loss: 0.169740\n",
      "Train Epoch: 7 | Batch Status: 24960/60000 (42%) | Loss: 0.026676\n",
      "Train Epoch: 7 | Batch Status: 25600/60000 (43%) | Loss: 0.073800\n",
      "Train Epoch: 7 | Batch Status: 26240/60000 (44%) | Loss: 0.025715\n",
      "Train Epoch: 7 | Batch Status: 26880/60000 (45%) | Loss: 0.105754\n",
      "Train Epoch: 7 | Batch Status: 27520/60000 (46%) | Loss: 0.083654\n",
      "Train Epoch: 7 | Batch Status: 28160/60000 (47%) | Loss: 0.058685\n",
      "Train Epoch: 7 | Batch Status: 28800/60000 (48%) | Loss: 0.069207\n",
      "Train Epoch: 7 | Batch Status: 29440/60000 (49%) | Loss: 0.085963\n",
      "Train Epoch: 7 | Batch Status: 30080/60000 (50%) | Loss: 0.151830\n",
      "Train Epoch: 7 | Batch Status: 30720/60000 (51%) | Loss: 0.279751\n",
      "Train Epoch: 7 | Batch Status: 31360/60000 (52%) | Loss: 0.119944\n",
      "Train Epoch: 7 | Batch Status: 32000/60000 (53%) | Loss: 0.149047\n",
      "Train Epoch: 7 | Batch Status: 32640/60000 (54%) | Loss: 0.040288\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7 | Batch Status: 33280/60000 (55%) | Loss: 0.174727\n",
      "Train Epoch: 7 | Batch Status: 33920/60000 (57%) | Loss: 0.092096\n",
      "Train Epoch: 7 | Batch Status: 34560/60000 (58%) | Loss: 0.095848\n",
      "Train Epoch: 7 | Batch Status: 35200/60000 (59%) | Loss: 0.095330\n",
      "Train Epoch: 7 | Batch Status: 35840/60000 (60%) | Loss: 0.122317\n",
      "Train Epoch: 7 | Batch Status: 36480/60000 (61%) | Loss: 0.130387\n",
      "Train Epoch: 7 | Batch Status: 37120/60000 (62%) | Loss: 0.130433\n",
      "Train Epoch: 7 | Batch Status: 37760/60000 (63%) | Loss: 0.190078\n",
      "Train Epoch: 7 | Batch Status: 38400/60000 (64%) | Loss: 0.058627\n",
      "Train Epoch: 7 | Batch Status: 39040/60000 (65%) | Loss: 0.198333\n",
      "Train Epoch: 7 | Batch Status: 39680/60000 (66%) | Loss: 0.047554\n",
      "Train Epoch: 7 | Batch Status: 40320/60000 (67%) | Loss: 0.090370\n",
      "Train Epoch: 7 | Batch Status: 40960/60000 (68%) | Loss: 0.074229\n",
      "Train Epoch: 7 | Batch Status: 41600/60000 (69%) | Loss: 0.073135\n",
      "Train Epoch: 7 | Batch Status: 42240/60000 (70%) | Loss: 0.121993\n",
      "Train Epoch: 7 | Batch Status: 42880/60000 (71%) | Loss: 0.165720\n",
      "Train Epoch: 7 | Batch Status: 43520/60000 (72%) | Loss: 0.143397\n",
      "Train Epoch: 7 | Batch Status: 44160/60000 (74%) | Loss: 0.195128\n",
      "Train Epoch: 7 | Batch Status: 44800/60000 (75%) | Loss: 0.100938\n",
      "Train Epoch: 7 | Batch Status: 45440/60000 (76%) | Loss: 0.120021\n",
      "Train Epoch: 7 | Batch Status: 46080/60000 (77%) | Loss: 0.128069\n",
      "Train Epoch: 7 | Batch Status: 46720/60000 (78%) | Loss: 0.138797\n",
      "Train Epoch: 7 | Batch Status: 47360/60000 (79%) | Loss: 0.047880\n",
      "Train Epoch: 7 | Batch Status: 48000/60000 (80%) | Loss: 0.076410\n",
      "Train Epoch: 7 | Batch Status: 48640/60000 (81%) | Loss: 0.150916\n",
      "Train Epoch: 7 | Batch Status: 49280/60000 (82%) | Loss: 0.068018\n",
      "Train Epoch: 7 | Batch Status: 49920/60000 (83%) | Loss: 0.156710\n",
      "Train Epoch: 7 | Batch Status: 50560/60000 (84%) | Loss: 0.147625\n",
      "Train Epoch: 7 | Batch Status: 51200/60000 (85%) | Loss: 0.128761\n",
      "Train Epoch: 7 | Batch Status: 51840/60000 (86%) | Loss: 0.138863\n",
      "Train Epoch: 7 | Batch Status: 52480/60000 (87%) | Loss: 0.217211\n",
      "Train Epoch: 7 | Batch Status: 53120/60000 (88%) | Loss: 0.074233\n",
      "Train Epoch: 7 | Batch Status: 53760/60000 (90%) | Loss: 0.057098\n",
      "Train Epoch: 7 | Batch Status: 54400/60000 (91%) | Loss: 0.108474\n",
      "Train Epoch: 7 | Batch Status: 55040/60000 (92%) | Loss: 0.060685\n",
      "Train Epoch: 7 | Batch Status: 55680/60000 (93%) | Loss: 0.205886\n",
      "Train Epoch: 7 | Batch Status: 56320/60000 (94%) | Loss: 0.052004\n",
      "Train Epoch: 7 | Batch Status: 56960/60000 (95%) | Loss: 0.241041\n",
      "Train Epoch: 7 | Batch Status: 57600/60000 (96%) | Loss: 0.101655\n",
      "Train Epoch: 7 | Batch Status: 58240/60000 (97%) | Loss: 0.077836\n",
      "Train Epoch: 7 | Batch Status: 58880/60000 (98%) | Loss: 0.085747\n",
      "Train Epoch: 7 | Batch Status: 59520/60000 (99%) | Loss: 0.083052\n",
      "Training time: 0m 14s\n",
      "===========================\n",
      "Test set: Average loss: 0.0020, Accuracy: 9636/10000 (96%)\n",
      "Testing time: 0m 16s\n",
      "Train Epoch: 8 | Batch Status: 0/60000 (0%) | Loss: 0.034428\n",
      "Train Epoch: 8 | Batch Status: 640/60000 (1%) | Loss: 0.031138\n",
      "Train Epoch: 8 | Batch Status: 1280/60000 (2%) | Loss: 0.318106\n",
      "Train Epoch: 8 | Batch Status: 1920/60000 (3%) | Loss: 0.147328\n",
      "Train Epoch: 8 | Batch Status: 2560/60000 (4%) | Loss: 0.079609\n",
      "Train Epoch: 8 | Batch Status: 3200/60000 (5%) | Loss: 0.048409\n",
      "Train Epoch: 8 | Batch Status: 3840/60000 (6%) | Loss: 0.067565\n",
      "Train Epoch: 8 | Batch Status: 4480/60000 (7%) | Loss: 0.369747\n",
      "Train Epoch: 8 | Batch Status: 5120/60000 (9%) | Loss: 0.247942\n",
      "Train Epoch: 8 | Batch Status: 5760/60000 (10%) | Loss: 0.100965\n",
      "Train Epoch: 8 | Batch Status: 6400/60000 (11%) | Loss: 0.064302\n",
      "Train Epoch: 8 | Batch Status: 7040/60000 (12%) | Loss: 0.074194\n",
      "Train Epoch: 8 | Batch Status: 7680/60000 (13%) | Loss: 0.057114\n",
      "Train Epoch: 8 | Batch Status: 8320/60000 (14%) | Loss: 0.122631\n",
      "Train Epoch: 8 | Batch Status: 8960/60000 (15%) | Loss: 0.169493\n",
      "Train Epoch: 8 | Batch Status: 9600/60000 (16%) | Loss: 0.075385\n",
      "Train Epoch: 8 | Batch Status: 10240/60000 (17%) | Loss: 0.050569\n",
      "Train Epoch: 8 | Batch Status: 10880/60000 (18%) | Loss: 0.060623\n",
      "Train Epoch: 8 | Batch Status: 11520/60000 (19%) | Loss: 0.064284\n",
      "Train Epoch: 8 | Batch Status: 12160/60000 (20%) | Loss: 0.117752\n",
      "Train Epoch: 8 | Batch Status: 12800/60000 (21%) | Loss: 0.070500\n",
      "Train Epoch: 8 | Batch Status: 13440/60000 (22%) | Loss: 0.257166\n",
      "Train Epoch: 8 | Batch Status: 14080/60000 (23%) | Loss: 0.047121\n",
      "Train Epoch: 8 | Batch Status: 14720/60000 (25%) | Loss: 0.086939\n",
      "Train Epoch: 8 | Batch Status: 15360/60000 (26%) | Loss: 0.078756\n",
      "Train Epoch: 8 | Batch Status: 16000/60000 (27%) | Loss: 0.078955\n",
      "Train Epoch: 8 | Batch Status: 16640/60000 (28%) | Loss: 0.050549\n",
      "Train Epoch: 8 | Batch Status: 17280/60000 (29%) | Loss: 0.117252\n",
      "Train Epoch: 8 | Batch Status: 17920/60000 (30%) | Loss: 0.078753\n",
      "Train Epoch: 8 | Batch Status: 18560/60000 (31%) | Loss: 0.026073\n",
      "Train Epoch: 8 | Batch Status: 19200/60000 (32%) | Loss: 0.050550\n",
      "Train Epoch: 8 | Batch Status: 19840/60000 (33%) | Loss: 0.078428\n",
      "Train Epoch: 8 | Batch Status: 20480/60000 (34%) | Loss: 0.188170\n",
      "Train Epoch: 8 | Batch Status: 21120/60000 (35%) | Loss: 0.112830\n",
      "Train Epoch: 8 | Batch Status: 21760/60000 (36%) | Loss: 0.113130\n",
      "Train Epoch: 8 | Batch Status: 22400/60000 (37%) | Loss: 0.114573\n",
      "Train Epoch: 8 | Batch Status: 23040/60000 (38%) | Loss: 0.118694\n",
      "Train Epoch: 8 | Batch Status: 23680/60000 (39%) | Loss: 0.180878\n",
      "Train Epoch: 8 | Batch Status: 24320/60000 (41%) | Loss: 0.228559\n",
      "Train Epoch: 8 | Batch Status: 24960/60000 (42%) | Loss: 0.080270\n",
      "Train Epoch: 8 | Batch Status: 25600/60000 (43%) | Loss: 0.169651\n",
      "Train Epoch: 8 | Batch Status: 26240/60000 (44%) | Loss: 0.141669\n",
      "Train Epoch: 8 | Batch Status: 26880/60000 (45%) | Loss: 0.049647\n",
      "Train Epoch: 8 | Batch Status: 27520/60000 (46%) | Loss: 0.045487\n",
      "Train Epoch: 8 | Batch Status: 28160/60000 (47%) | Loss: 0.087871\n",
      "Train Epoch: 8 | Batch Status: 28800/60000 (48%) | Loss: 0.166746\n",
      "Train Epoch: 8 | Batch Status: 29440/60000 (49%) | Loss: 0.174123\n",
      "Train Epoch: 8 | Batch Status: 30080/60000 (50%) | Loss: 0.126898\n",
      "Train Epoch: 8 | Batch Status: 30720/60000 (51%) | Loss: 0.126917\n",
      "Train Epoch: 8 | Batch Status: 31360/60000 (52%) | Loss: 0.061717\n",
      "Train Epoch: 8 | Batch Status: 32000/60000 (53%) | Loss: 0.301279\n",
      "Train Epoch: 8 | Batch Status: 32640/60000 (54%) | Loss: 0.050950\n",
      "Train Epoch: 8 | Batch Status: 33280/60000 (55%) | Loss: 0.107814\n",
      "Train Epoch: 8 | Batch Status: 33920/60000 (57%) | Loss: 0.126119\n",
      "Train Epoch: 8 | Batch Status: 34560/60000 (58%) | Loss: 0.185832\n",
      "Train Epoch: 8 | Batch Status: 35200/60000 (59%) | Loss: 0.079017\n",
      "Train Epoch: 8 | Batch Status: 35840/60000 (60%) | Loss: 0.054532\n",
      "Train Epoch: 8 | Batch Status: 36480/60000 (61%) | Loss: 0.108783\n",
      "Train Epoch: 8 | Batch Status: 37120/60000 (62%) | Loss: 0.096714\n",
      "Train Epoch: 8 | Batch Status: 37760/60000 (63%) | Loss: 0.051845\n",
      "Train Epoch: 8 | Batch Status: 38400/60000 (64%) | Loss: 0.235586\n",
      "Train Epoch: 8 | Batch Status: 39040/60000 (65%) | Loss: 0.223957\n",
      "Train Epoch: 8 | Batch Status: 39680/60000 (66%) | Loss: 0.090151\n",
      "Train Epoch: 8 | Batch Status: 40320/60000 (67%) | Loss: 0.113622\n",
      "Train Epoch: 8 | Batch Status: 40960/60000 (68%) | Loss: 0.129909\n",
      "Train Epoch: 8 | Batch Status: 41600/60000 (69%) | Loss: 0.061211\n",
      "Train Epoch: 8 | Batch Status: 42240/60000 (70%) | Loss: 0.052321\n",
      "Train Epoch: 8 | Batch Status: 42880/60000 (71%) | Loss: 0.049765\n",
      "Train Epoch: 8 | Batch Status: 43520/60000 (72%) | Loss: 0.138108\n",
      "Train Epoch: 8 | Batch Status: 44160/60000 (74%) | Loss: 0.056794\n",
      "Train Epoch: 8 | Batch Status: 44800/60000 (75%) | Loss: 0.079831\n",
      "Train Epoch: 8 | Batch Status: 45440/60000 (76%) | Loss: 0.045735\n",
      "Train Epoch: 8 | Batch Status: 46080/60000 (77%) | Loss: 0.160201\n",
      "Train Epoch: 8 | Batch Status: 46720/60000 (78%) | Loss: 0.167711\n",
      "Train Epoch: 8 | Batch Status: 47360/60000 (79%) | Loss: 0.070292\n",
      "Train Epoch: 8 | Batch Status: 48000/60000 (80%) | Loss: 0.074587\n",
      "Train Epoch: 8 | Batch Status: 48640/60000 (81%) | Loss: 0.035178\n",
      "Train Epoch: 8 | Batch Status: 49280/60000 (82%) | Loss: 0.057078\n",
      "Train Epoch: 8 | Batch Status: 49920/60000 (83%) | Loss: 0.081941\n",
      "Train Epoch: 8 | Batch Status: 50560/60000 (84%) | Loss: 0.078871\n",
      "Train Epoch: 8 | Batch Status: 51200/60000 (85%) | Loss: 0.059255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 8 | Batch Status: 51840/60000 (86%) | Loss: 0.094631\n",
      "Train Epoch: 8 | Batch Status: 52480/60000 (87%) | Loss: 0.148708\n",
      "Train Epoch: 8 | Batch Status: 53120/60000 (88%) | Loss: 0.164442\n",
      "Train Epoch: 8 | Batch Status: 53760/60000 (90%) | Loss: 0.044825\n",
      "Train Epoch: 8 | Batch Status: 54400/60000 (91%) | Loss: 0.115247\n",
      "Train Epoch: 8 | Batch Status: 55040/60000 (92%) | Loss: 0.097088\n",
      "Train Epoch: 8 | Batch Status: 55680/60000 (93%) | Loss: 0.107191\n",
      "Train Epoch: 8 | Batch Status: 56320/60000 (94%) | Loss: 0.033839\n",
      "Train Epoch: 8 | Batch Status: 56960/60000 (95%) | Loss: 0.083385\n",
      "Train Epoch: 8 | Batch Status: 57600/60000 (96%) | Loss: 0.398748\n",
      "Train Epoch: 8 | Batch Status: 58240/60000 (97%) | Loss: 0.097746\n",
      "Train Epoch: 8 | Batch Status: 58880/60000 (98%) | Loss: 0.061618\n",
      "Train Epoch: 8 | Batch Status: 59520/60000 (99%) | Loss: 0.088802\n",
      "Training time: 0m 16s\n",
      "===========================\n",
      "Test set: Average loss: 0.0018, Accuracy: 9652/10000 (97%)\n",
      "Testing time: 0m 17s\n",
      "Train Epoch: 9 | Batch Status: 0/60000 (0%) | Loss: 0.064522\n",
      "Train Epoch: 9 | Batch Status: 640/60000 (1%) | Loss: 0.032077\n",
      "Train Epoch: 9 | Batch Status: 1280/60000 (2%) | Loss: 0.087666\n",
      "Train Epoch: 9 | Batch Status: 1920/60000 (3%) | Loss: 0.045696\n",
      "Train Epoch: 9 | Batch Status: 2560/60000 (4%) | Loss: 0.171176\n",
      "Train Epoch: 9 | Batch Status: 3200/60000 (5%) | Loss: 0.120226\n",
      "Train Epoch: 9 | Batch Status: 3840/60000 (6%) | Loss: 0.073276\n",
      "Train Epoch: 9 | Batch Status: 4480/60000 (7%) | Loss: 0.050297\n",
      "Train Epoch: 9 | Batch Status: 5120/60000 (9%) | Loss: 0.058434\n",
      "Train Epoch: 9 | Batch Status: 5760/60000 (10%) | Loss: 0.230200\n",
      "Train Epoch: 9 | Batch Status: 6400/60000 (11%) | Loss: 0.154790\n",
      "Train Epoch: 9 | Batch Status: 7040/60000 (12%) | Loss: 0.094010\n",
      "Train Epoch: 9 | Batch Status: 7680/60000 (13%) | Loss: 0.074970\n",
      "Train Epoch: 9 | Batch Status: 8320/60000 (14%) | Loss: 0.126541\n",
      "Train Epoch: 9 | Batch Status: 8960/60000 (15%) | Loss: 0.018822\n",
      "Train Epoch: 9 | Batch Status: 9600/60000 (16%) | Loss: 0.099191\n",
      "Train Epoch: 9 | Batch Status: 10240/60000 (17%) | Loss: 0.059333\n",
      "Train Epoch: 9 | Batch Status: 10880/60000 (18%) | Loss: 0.070055\n",
      "Train Epoch: 9 | Batch Status: 11520/60000 (19%) | Loss: 0.058061\n",
      "Train Epoch: 9 | Batch Status: 12160/60000 (20%) | Loss: 0.141740\n",
      "Train Epoch: 9 | Batch Status: 12800/60000 (21%) | Loss: 0.077488\n",
      "Train Epoch: 9 | Batch Status: 13440/60000 (22%) | Loss: 0.057760\n",
      "Train Epoch: 9 | Batch Status: 14080/60000 (23%) | Loss: 0.210085\n",
      "Train Epoch: 9 | Batch Status: 14720/60000 (25%) | Loss: 0.158125\n",
      "Train Epoch: 9 | Batch Status: 15360/60000 (26%) | Loss: 0.053329\n",
      "Train Epoch: 9 | Batch Status: 16000/60000 (27%) | Loss: 0.027698\n",
      "Train Epoch: 9 | Batch Status: 16640/60000 (28%) | Loss: 0.028353\n",
      "Train Epoch: 9 | Batch Status: 17280/60000 (29%) | Loss: 0.056297\n",
      "Train Epoch: 9 | Batch Status: 17920/60000 (30%) | Loss: 0.054272\n",
      "Train Epoch: 9 | Batch Status: 18560/60000 (31%) | Loss: 0.182997\n",
      "Train Epoch: 9 | Batch Status: 19200/60000 (32%) | Loss: 0.084630\n",
      "Train Epoch: 9 | Batch Status: 19840/60000 (33%) | Loss: 0.094974\n",
      "Train Epoch: 9 | Batch Status: 20480/60000 (34%) | Loss: 0.038184\n",
      "Train Epoch: 9 | Batch Status: 21120/60000 (35%) | Loss: 0.099507\n",
      "Train Epoch: 9 | Batch Status: 21760/60000 (36%) | Loss: 0.119059\n",
      "Train Epoch: 9 | Batch Status: 22400/60000 (37%) | Loss: 0.064935\n",
      "Train Epoch: 9 | Batch Status: 23040/60000 (38%) | Loss: 0.135770\n",
      "Train Epoch: 9 | Batch Status: 23680/60000 (39%) | Loss: 0.019958\n",
      "Train Epoch: 9 | Batch Status: 24320/60000 (41%) | Loss: 0.056561\n",
      "Train Epoch: 9 | Batch Status: 24960/60000 (42%) | Loss: 0.225709\n",
      "Train Epoch: 9 | Batch Status: 25600/60000 (43%) | Loss: 0.027976\n",
      "Train Epoch: 9 | Batch Status: 26240/60000 (44%) | Loss: 0.028653\n",
      "Train Epoch: 9 | Batch Status: 26880/60000 (45%) | Loss: 0.087735\n",
      "Train Epoch: 9 | Batch Status: 27520/60000 (46%) | Loss: 0.064792\n",
      "Train Epoch: 9 | Batch Status: 28160/60000 (47%) | Loss: 0.069144\n",
      "Train Epoch: 9 | Batch Status: 28800/60000 (48%) | Loss: 0.129700\n",
      "Train Epoch: 9 | Batch Status: 29440/60000 (49%) | Loss: 0.024540\n",
      "Train Epoch: 9 | Batch Status: 30080/60000 (50%) | Loss: 0.195715\n",
      "Train Epoch: 9 | Batch Status: 30720/60000 (51%) | Loss: 0.120158\n",
      "Train Epoch: 9 | Batch Status: 31360/60000 (52%) | Loss: 0.174468\n",
      "Train Epoch: 9 | Batch Status: 32000/60000 (53%) | Loss: 0.042582\n",
      "Train Epoch: 9 | Batch Status: 32640/60000 (54%) | Loss: 0.303382\n",
      "Train Epoch: 9 | Batch Status: 33280/60000 (55%) | Loss: 0.063159\n",
      "Train Epoch: 9 | Batch Status: 33920/60000 (57%) | Loss: 0.087497\n",
      "Train Epoch: 9 | Batch Status: 34560/60000 (58%) | Loss: 0.143681\n",
      "Train Epoch: 9 | Batch Status: 35200/60000 (59%) | Loss: 0.114401\n",
      "Train Epoch: 9 | Batch Status: 35840/60000 (60%) | Loss: 0.139382\n",
      "Train Epoch: 9 | Batch Status: 36480/60000 (61%) | Loss: 0.106451\n",
      "Train Epoch: 9 | Batch Status: 37120/60000 (62%) | Loss: 0.030202\n",
      "Train Epoch: 9 | Batch Status: 37760/60000 (63%) | Loss: 0.204522\n",
      "Train Epoch: 9 | Batch Status: 38400/60000 (64%) | Loss: 0.064196\n",
      "Train Epoch: 9 | Batch Status: 39040/60000 (65%) | Loss: 0.126408\n",
      "Train Epoch: 9 | Batch Status: 39680/60000 (66%) | Loss: 0.139973\n",
      "Train Epoch: 9 | Batch Status: 40320/60000 (67%) | Loss: 0.072938\n",
      "Train Epoch: 9 | Batch Status: 40960/60000 (68%) | Loss: 0.051805\n",
      "Train Epoch: 9 | Batch Status: 41600/60000 (69%) | Loss: 0.030537\n",
      "Train Epoch: 9 | Batch Status: 42240/60000 (70%) | Loss: 0.036604\n",
      "Train Epoch: 9 | Batch Status: 42880/60000 (71%) | Loss: 0.054448\n",
      "Train Epoch: 9 | Batch Status: 43520/60000 (72%) | Loss: 0.058042\n",
      "Train Epoch: 9 | Batch Status: 44160/60000 (74%) | Loss: 0.047236\n",
      "Train Epoch: 9 | Batch Status: 44800/60000 (75%) | Loss: 0.066011\n",
      "Train Epoch: 9 | Batch Status: 45440/60000 (76%) | Loss: 0.031827\n",
      "Train Epoch: 9 | Batch Status: 46080/60000 (77%) | Loss: 0.121631\n",
      "Train Epoch: 9 | Batch Status: 46720/60000 (78%) | Loss: 0.213369\n",
      "Train Epoch: 9 | Batch Status: 47360/60000 (79%) | Loss: 0.078691\n",
      "Train Epoch: 9 | Batch Status: 48000/60000 (80%) | Loss: 0.140456\n",
      "Train Epoch: 9 | Batch Status: 48640/60000 (81%) | Loss: 0.155740\n",
      "Train Epoch: 9 | Batch Status: 49280/60000 (82%) | Loss: 0.100970\n",
      "Train Epoch: 9 | Batch Status: 49920/60000 (83%) | Loss: 0.155180\n",
      "Train Epoch: 9 | Batch Status: 50560/60000 (84%) | Loss: 0.060220\n",
      "Train Epoch: 9 | Batch Status: 51200/60000 (85%) | Loss: 0.086183\n",
      "Train Epoch: 9 | Batch Status: 51840/60000 (86%) | Loss: 0.116751\n",
      "Train Epoch: 9 | Batch Status: 52480/60000 (87%) | Loss: 0.053996\n",
      "Train Epoch: 9 | Batch Status: 53120/60000 (88%) | Loss: 0.305893\n",
      "Train Epoch: 9 | Batch Status: 53760/60000 (90%) | Loss: 0.108458\n",
      "Train Epoch: 9 | Batch Status: 54400/60000 (91%) | Loss: 0.047701\n",
      "Train Epoch: 9 | Batch Status: 55040/60000 (92%) | Loss: 0.037686\n",
      "Train Epoch: 9 | Batch Status: 55680/60000 (93%) | Loss: 0.050662\n",
      "Train Epoch: 9 | Batch Status: 56320/60000 (94%) | Loss: 0.144859\n",
      "Train Epoch: 9 | Batch Status: 56960/60000 (95%) | Loss: 0.027137\n",
      "Train Epoch: 9 | Batch Status: 57600/60000 (96%) | Loss: 0.112016\n",
      "Train Epoch: 9 | Batch Status: 58240/60000 (97%) | Loss: 0.186713\n",
      "Train Epoch: 9 | Batch Status: 58880/60000 (98%) | Loss: 0.054401\n",
      "Train Epoch: 9 | Batch Status: 59520/60000 (99%) | Loss: 0.151418\n",
      "Training time: 0m 19s\n",
      "===========================\n",
      "Test set: Average loss: 0.0017, Accuracy: 9684/10000 (97%)\n",
      "Testing time: 0m 21s\n",
      "Total Time: 2m 39s\n",
      "Model was trained on cpu!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    since = time.time()\n",
    "    for epoch in range(1, 10):\n",
    "        epoch_start = time.time()\n",
    "        train(epoch)\n",
    "        m, s = divmod(time.time() - epoch_start, 60)\n",
    "        print(f'Training time: {m:.0f}m {s:.0f}s')\n",
    "        test()\n",
    "        m, s = divmod(time.time() - epoch_start, 60)\n",
    "        print(f'Testing time: {m:.0f}m {s:.0f}s')\n",
    "\n",
    "    m, s = divmod(time.time() - since, 60)\n",
    "    print(f'Total Time: {m:.0f}m {s:.0f}s\\nModel was trained on {device}!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
